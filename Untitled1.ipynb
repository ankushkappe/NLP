{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yjfli-IHzw1o"
      },
      "outputs": [],
      "source": [
        "sentence1 = \"The quick brown fox jumps over the lazy dog.\"\n",
        "sentence2 = \"A brown fox jumps over a lazy dog.\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "h4zei_wVz4oR",
        "outputId": "5608708d-2d5e-4270-a498-4401387e036f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for stop-word removal\n",
        "def remove_stop_words(sentence):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = word_tokenize(sentence.lower())\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    return ' '.join(filtered_tokens)\n"
      ],
      "metadata": {
        "id": "kzEbJtND0CsG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Function for vector encoding\n",
        "def vector_encode(sentence1, sentence2, encoding_type='tfidf'):\n",
        "    if encoding_type == 'one-hot':\n",
        "        vectorizer = TfidfVectorizer(binary=True)\n",
        "    elif encoding_type == 'bag-of-words':\n",
        "        vectorizer = TfidfVectorizer()\n",
        "    elif encoding_type == 'tf':\n",
        "        vectorizer = TfidfVectorizer(use_idf=False)\n",
        "    else:\n",
        "        vectorizer = TfidfVectorizer()\n",
        "\n",
        "    X = vectorizer.fit_transform([sentence1, sentence2])\n",
        "    return X\n"
      ],
      "metadata": {
        "id": "trt8jaPg0LE2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample pair of sentences\n",
        "sentence1 = \"The quick brown fox jumps over the lazy dog.\"\n",
        "sentence2 = \"A brown fox jumps over a lazy dog.\"\n",
        "\n",
        "# Encode the sentences using different encoding types\n",
        "X_tfidf = vector_encode(sentence1, sentence2, encoding_type='tfidf')\n",
        "X_tf = vector_encode(sentence1, sentence2, encoding_type='tf')\n",
        "\n",
        "# Print the encoded matrices\n",
        "print(\"TF-IDF Encoding:\")\n",
        "print(X_tfidf.toarray())\n",
        "print(\"\\nTF Encoding:\")\n",
        "print(X_tf.toarray())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cndKQBdD0T9F",
        "outputId": "ec30649b-2083-4937-9b89-d4fceb93f5ff"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Encoding:\n",
            "[[0.25096919 0.25096919 0.25096919 0.25096919 0.25096919 0.25096919\n",
            "  0.35272845 0.70545689]\n",
            " [0.40824829 0.40824829 0.40824829 0.40824829 0.40824829 0.40824829\n",
            "  0.         0.        ]]\n",
            "\n",
            "TF Encoding:\n",
            "[[0.30151134 0.30151134 0.30151134 0.30151134 0.30151134 0.30151134\n",
            "  0.30151134 0.60302269]\n",
            " [0.40824829 0.40824829 0.40824829 0.40824829 0.40824829 0.40824829\n",
            "  0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Compute cosine similarity\n",
        "similarity_tfidf = cosine_similarity(X_tfidf)\n",
        "similarity_tf = cosine_similarity(X_tf)\n",
        "\n",
        "# Print the similarity scores\n",
        "print(\"Similarity score (TF-IDF):\", similarity_tfidf)\n",
        "print(\"Similarity score (TF):\", similarity_tf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "eONcp3Xa0oXQ",
        "outputId": "24f9087b-f3a1-4934-f388-cae563475e52"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score (TF-IDF): [[1.         0.61474647]\n",
            " [0.61474647 1.        ]]\n",
            "Similarity score (TF): [[1.         0.73854895]\n",
            " [0.73854895 1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Preprocessing - Remove stop words\n",
        "processed_sentence1 = remove_stop_words(sentence1)\n",
        "processed_sentence2 = remove_stop_words(sentence2)\n",
        "\n",
        "print(\"Processed Sentence 1:\", processed_sentence1)\n",
        "print(\"Processed Sentence 2:\", processed_sentence2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "DdREgkTi1jgv",
        "outputId": "5519ebc1-93bf-4f67-c5df-16a4bc7edf6b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed Sentence 1: quick brown fox jumps lazy dog .\n",
            "Processed Sentence 2: brown fox jumps lazy dog .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Encode the preprocessed sentences using TF-IDF and TF encodings\n",
        "X_tfidf = vector_encode(processed_sentence1, processed_sentence2, encoding_type='tfidf')\n",
        "X_tf = vector_encode(processed_sentence1, processed_sentence2, encoding_type='tf')\n",
        "\n",
        "print(\"TF-IDF Encoding:\")\n",
        "print(X_tfidf.toarray())\n",
        "print(\"\\nTF Encoding:\")\n",
        "print(X_tf.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wHdM0VRT1tEf",
        "outputId": "7b5e02b9-71b2-4dbf-a233-f18ae8c3ee9e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Encoding:\n",
            "[[0.37863221 0.37863221 0.37863221 0.37863221 0.37863221 0.53215436]\n",
            " [0.4472136  0.4472136  0.4472136  0.4472136  0.4472136  0.        ]]\n",
            "\n",
            "TF Encoding:\n",
            "[[0.40824829 0.40824829 0.40824829 0.40824829 0.40824829 0.40824829]\n",
            " [0.4472136  0.4472136  0.4472136  0.4472136  0.4472136  0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for computing similarity\n",
        "def compute_similarity(X):\n",
        "    return cosine_similarity(X[0], X[1])[0][0]"
      ],
      "metadata": {
        "id": "9_YtC9c82But"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Encode the preprocessed sentences using TF-IDF and TF encodings\n",
        "X_tfidf = vector_encode(processed_sentence1, processed_sentence2, encoding_type='tfidf')\n",
        "X_tf = vector_encode(processed_sentence1, processed_sentence2, encoding_type='tf')\n",
        "\n",
        "print(\"TF-IDF Encoding:\")\n",
        "print(X_tfidf.toarray())\n",
        "print(\"\\nTF Encoding:\")\n",
        "print(X_tf.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-t-PPxNt2F8s",
        "outputId": "43d1820f-4a19-421d-9cac-be2e62996575"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Encoding:\n",
            "[[0.37863221 0.37863221 0.37863221 0.37863221 0.37863221 0.53215436]\n",
            " [0.4472136  0.4472136  0.4472136  0.4472136  0.4472136  0.        ]]\n",
            "\n",
            "TF Encoding:\n",
            "[[0.40824829 0.40824829 0.40824829 0.40824829 0.40824829 0.40824829]\n",
            " [0.4472136  0.4472136  0.4472136  0.4472136  0.4472136  0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Compute similarity scores\n",
        "similarity_tfidf = compute_similarity(X_tfidf)\n",
        "similarity_tf = compute_similarity(X_tf)\n",
        "\n",
        "print(\"Similarity score (TF-IDF):\", similarity_tfidf)\n",
        "print(\"Similarity score (TF):\", similarity_tf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "J0x3uJpu3GBG",
        "outputId": "e361bfb7-f75a-4a24-b255-a1f7d8a5b5a8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score (TF-IDF): 0.8466473536503034\n",
            "Similarity score (TF): 0.912870929175277\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Test Case 2**"
      ],
      "metadata": {
        "id": "Rg-9HG26COmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Define the sentences\n",
        "sentence1 = \"The sun rises in the east.\"\n",
        "sentence2 = \"The moon sets in the west.\"\n",
        "\n",
        "# Tokenize the sentences\n",
        "tokenized_sentence1 = word_tokenize(sentence1)\n",
        "tokenized_sentence2 = word_tokenize(sentence2)\n",
        "\n",
        "# Print the tokenized sentences\n",
        "print(\"Tokenized Sentence 1:\", tokenized_sentence1)\n",
        "print(\"Tokenized Sentence 2:\", tokenized_sentence2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MJ2wP8Sf5s08",
        "outputId": "955310cd-b813-4338-a097-c311fdd60e5e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized Sentence 1: ['The', 'sun', 'rises', 'in', 'the', 'east', '.']\n",
            "Tokenized Sentence 2: ['The', 'moon', 'sets', 'in', 'the', 'west', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n"
      ],
      "metadata": {
        "id": "kZCARW8T62g_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n"
      ],
      "metadata": {
        "id": "4bZ6hWEA662y"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_sentence1 = [word for word in tokenized_sentence1 if word.lower() not in stop_words]\n",
        "filtered_sentence2 = [word for word in tokenized_sentence2 if word.lower() not in stop_words]\n"
      ],
      "metadata": {
        "id": "T92klsn469dV"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Filtered Sentence 1:\", filtered_sentence1)\n",
        "print(\"Filtered Sentence 2:\", filtered_sentence2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4ODnLxXz7BeD",
        "outputId": "9312da6d-fc20-46a8-e5e6-e9fbebe89ccb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered Sentence 1: ['sun', 'rises', 'east', '.']\n",
            "Filtered Sentence 2: ['moon', 'sets', 'west', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n"
      ],
      "metadata": {
        "id": "Q749Wc5E8ayf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ps = PorterStemmer()\n"
      ],
      "metadata": {
        "id": "wZjlZemu8dyM"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmed_sentence1 = [ps.stem(word) for word in filtered_sentence1]\n",
        "stemmed_sentence2 = [ps.stem(word) for word in filtered_sentence2]\n"
      ],
      "metadata": {
        "id": "MfcuHMgW8gUo"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Stemmed Sentence 1:\", stemmed_sentence1)\n",
        "print(\"Stemmed Sentence 2:\", stemmed_sentence2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TwQzDLt28i8L",
        "outputId": "d4a0baee-89f2-4ef2-b514-b50f09877f7a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemmed Sentence 1: ['sun', 'rise', 'east', '.']\n",
            "Stemmed Sentence 2: ['moon', 'set', 'west', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "\n",
        "# Initialize TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_tfidf = tfidf_vectorizer.fit_transform([' '.join(stemmed_sentence1), ' '.join(stemmed_sentence2)])\n",
        "\n",
        "# Initialize TF vectorizer\n",
        "tf_vectorizer = CountVectorizer()\n",
        "X_tf = tf_vectorizer.fit_transform([' '.join(stemmed_sentence1), ' '.join(stemmed_sentence2)])\n",
        "\n",
        "# Print the encoded vectors\n",
        "print(\"TF-IDF Encoding:\")\n",
        "print(X_tfidf.toarray())\n",
        "print(\"\\nTF Encoding:\")\n",
        "print(X_tf.toarray())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KxggQ7gG8rlH",
        "outputId": "ed5bded8-d437-456d-ee2d-d7c6a5b29643"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Encoding:\n",
            "[[0.57735027 0.         0.57735027 0.         0.57735027 0.        ]\n",
            " [0.         0.57735027 0.         0.57735027 0.         0.57735027]]\n",
            "\n",
            "TF Encoding:\n",
            "[[1 0 1 0 1 0]\n",
            " [0 1 0 1 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Compute similarity scores\n",
        "similarity_tfidf = cosine_similarity(X_tfidf)\n",
        "similarity_tf = cosine_similarity(X_tf)\n",
        "\n",
        "# Print the similarity scores\n",
        "print(\"Similarity score (TF-IDF):\", similarity_tfidf)\n",
        "print(\"Similarity score (TF):\", similarity_tf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "UhemC_Np81OI",
        "outputId": "641e852c-f9fd-4802-b2cd-7f2494c3820e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score (TF-IDF): [[1. 0.]\n",
            " [0. 1.]]\n",
            "Similarity score (TF): [[1. 0.]\n",
            " [0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Case **3**"
      ],
      "metadata": {
        "id": "k9Cv1M_wBwuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence1 = \"The cat is sitting on the mat.\"\n",
        "sentence2 = \"The dog is lying on the rug.\""
      ],
      "metadata": {
        "id": "nkwulq689UCg"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence1_processed = remove_stop_words(sentence1)\n",
        "sentence2_processed = remove_stop_words(sentence2)\n",
        "\n",
        "print(\"Processed Sentence 1:\", sentence1_processed)\n",
        "print(\"Processed Sentence 2:\", sentence2_processed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GsLd3w5w93J-",
        "outputId": "95e2f421-e887-47bc-b9d1-200e1d6788d5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed Sentence 1: cat sitting mat .\n",
            "Processed Sentence 2: dog lying rug .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the sentences\n",
        "X_tfidf = vector_encode(sentence1_processed, sentence2_processed, encoding_type='tfidf')\n",
        "X_tf = vector_encode(sentence1_processed, sentence2_processed, encoding_type='tf')\n",
        "\n",
        "print(\"TF-IDF Encoding:\")\n",
        "print(X_tfidf.toarray())\n",
        "print(\"\\nTF Encoding:\")\n",
        "print(X_tf.toarray())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TO-J4JOt-Lek",
        "outputId": "f12adb59-0e41-4dd7-ddc1-2cdcbfd092e1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Encoding:\n",
            "[[0.57735027 0.         0.         0.57735027 0.         0.57735027]\n",
            " [0.         0.57735027 0.57735027 0.         0.57735027 0.        ]]\n",
            "\n",
            "TF Encoding:\n",
            "[[0.57735027 0.         0.         0.57735027 0.         0.57735027]\n",
            " [0.         0.57735027 0.57735027 0.         0.57735027 0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute similarity scores\n",
        "similarity_tfidf = compute_similarity(X_tfidf)\n",
        "similarity_tf = compute_similarity(X_tf)\n",
        "\n",
        "print(\"Similarity score (TF-IDF):\", similarity_tfidf)\n",
        "print(\"Similarity score (TF):\", similarity_tf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pV8Y450Q-YkQ",
        "outputId": "05918ded-04b3-459b-b679-4d574d6fdfe5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score (TF-IDF): 0.0\n",
            "Similarity score (TF): 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Define the sentences\n",
        "sentence1 = \"The quick brown fox jumps over the lazy dog.\"\n",
        "sentence2 = \"A red fox leaps over a sleeping cat.\"\n",
        "\n",
        "# Tokenize the sentences\n",
        "tokenized_sentence1 = word_tokenize(sentence1)\n",
        "tokenized_sentence2 = word_tokenize(sentence2)\n",
        "\n",
        "# Print the tokenized sentences\n",
        "print(\"Tokenized Sentence 1:\", tokenized_sentence1)\n",
        "print(\"Tokenized Sentence 2:\", tokenized_sentence2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jb5K-CHo_NgS",
        "outputId": "62202c58-7c87-44c8-9a43-b55d05bbce3c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized Sentence 1: ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n",
            "Tokenized Sentence 2: ['A', 'red', 'fox', 'leaps', 'over', 'a', 'sleeping', 'cat', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "\n",
        "# Initialize TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_tfidf = tfidf_vectorizer.fit_transform([' '.join(stemmed_sentence1), ' '.join(stemmed_sentence2)])\n",
        "\n",
        "# Initialize TF vectorizer\n",
        "tf_vectorizer = CountVectorizer()\n",
        "X_tf = tf_vectorizer.fit_transform([' '.join(stemmed_sentence1), ' '.join(stemmed_sentence2)])\n",
        "\n",
        "# Print the encoded vectors\n",
        "print(\"TF-IDF Encoding:\")\n",
        "print(X_tfidf.toarray())\n",
        "print(\"\\nTF Encoding:\")\n",
        "print(X_tf.toarray())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "J_9T5MBe_m2g",
        "outputId": "777fb100-d036-40d4-fb28-977daf5abce0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Encoding:\n",
            "[[0.57735027 0.         0.57735027 0.         0.57735027 0.        ]\n",
            " [0.         0.57735027 0.         0.57735027 0.         0.57735027]]\n",
            "\n",
            "TF Encoding:\n",
            "[[1 0 1 0 1 0]\n",
            " [0 1 0 1 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute similarity scores\n",
        "similarity_tfidf = compute_similarity(X_tfidf)\n",
        "similarity_tf = compute_similarity(X_tf)\n",
        "\n",
        "print(\"Similarity score (TF-IDF):\", similarity_tfidf)\n",
        "print(\"Similarity score (TF):\", similarity_tf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "AoJScqeiATFa",
        "outputId": "0b4e2277-ed18-4cd7-ba2a-23585d2ff9d0"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity score (TF-IDF): 0.0\n",
            "Similarity score (TF): 0.0\n"
          ]
        }
      ]
    }
  ]
}